\documentclass[10pt, conference, compsocconf]{IEEEtran}
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{cite}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{algorithmic}

\begin{document}
\bibliographystyle{IEEEtran}

%\title{Online Training Machine Learning based Decision Maker for Mobile
%Offloading Framework}
\title{Machine Learning-based Mobile Offloading Scheduler with Online
Training}


\author{\IEEEauthorblockN{Heungsik Eom, Renato Figueiredo}
\IEEEauthorblockA{Advanced Computing and Information Systems Laboratory\\
Electrical and Computer Engineering\\
University of Florida, Gainesville, Florida, USA\\
\{hseom, renato\}@acis.ufl.edu}
\and
\IEEEauthorblockN{Huaqian Cai, Gang Huang}
\IEEEauthorblockA{Operating System and Middleware Laboratory\\
School of Electronics Engineering and Computer Science\\
Peking University, Beijing, China\\
\{caihq12, hg\}@pku.edu.cn}
}

\maketitle

\begin{abstract}
%
%OpenCL has emerged as the open standard for parallel programming for
%heterogeneous platforms enabling a uniform framework to discover,
%program, and distribute parallel workloads to the diverse set of compute
%units in the hardware.
%
%For that reason, there have been efforts exploring the advantages of
%parallelism from the OpenCL framework by offloading GPGPU workloads
%within an HPC cluster environment.
%
%In this paper, we present an OpenCL-based remote offloading framework
%designed for mobile platforms by shifting the motivation and
%advantages of using the OpenCL framework for the HPC cluster environment
%into mobile cloud computing where OpenCL workloads can be exported from
%a mobile node to the cloud.
%
%Furthermore, our offloading framework handles service discovery, access
%control, and data privacy by building the framework on top of a social
%peer-to-peer virtual private network, SocialVPN. 
%
%We developed a prototype implementation and deployed it into local- and
%wide-area environments to evaluate the performance improvement and
%energy implications of the proposed offloading framework.
%
%Our results show that, depending on the complexity of the workload and
%the amount of data transfer, the proposed architecture can achieve more
%energy efficient performance by offloading than executing locally.
\end{abstract}

\begin{IEEEkeywords}
Mobile platform, computation offloading, machine learning, runtime
scheduler, online training
\end{IEEEkeywords}

\section{Introduction}
%
Over the last decade, mobile offloading techniques have emerged as
a means to overcome resource constraints of mobile platforms (i.e.
smartphones, tablets).
%
Offloading allows these devices to delegate computationally-intensive
tasks to more powerful external resource, such as personal workstations
or cloud servers.
%
Initially, research interests on mobile offloading techniques
have focused on core mechanisms that deal primarily with \textit{what to
offload} and \textit{how to offload}.
%
The research community has studied various approaches to implement mobile
offloading frameworks which fall in the following categories:
application partitioning~\cite{spectra, maui, cuckoo}, thread
migration~\cite{clonecloud, comet}, application migration~\cite{hung},
and distributed offloading frameworks~\cite{mmr, serendipity}.\\
%
\indent However, one important fact is that benefits and drawbacks
from offloading computation-intensive portions of mobile applications
can be influenced by various internal and external factors, such as
applications requirements, network conditions, and computing
capabilities of mobile and external devices. 
%
Thus, \textit{whether to offload or execute locally} needs to be
decided dynamically, and the decision-making can benefit from monitoring
the aforementioned dynamic features at runtime.
%
Otherwise, incorrect offloading decisions may cause performance
degradation and/or increase energy consumption.
%
Related work has also considered dynamic scheduling for mobile
offloading frameworks.
%
For example, Kwon et al.~\cite{kwon} consider a simple rule-based
scheduler in which the framework decides to offload  mobile
computations only when the data transfer size is higher than a certain
threshold.
%
MAUI~\cite{maui} utilizes a linear regression model using predefined
features to make offloading decisions.\\
%
\indent Even though these systems consider runtime schedulers for mobile
offloading, which take dynamic features such as data transfer size or
network conditions into account to make offloading decisions, it is
impractical for these approaches to build a comprehensive well-defined
offloading decision policy embracing all possible cases over dynamic
mobile environments.
% 
Furthermore, it is difficult to generally apply the above efforts to
various applications, since each application has its own requirements or
characteristics.
%
For example, gaming and image processing application may have different
computating complexity of the amonut of computations, though they
process a similar size of data.
%
Therefore, in practice, ths mobile offloading scheduler has to work
independently with the type of applications without any predefined
decision rules.\\ 
%
\indent In this paper, we aim to develop a general framework for an
adaptive scheduler for mobile offloading by employing online, runtime
machine learning techniques.
%
In this approach, a machine learning classifier makes decisions of
whether mobile computations should be offloaded to external resources,
or executed locally. 
%
To this end, we extend our previous work on offline machine
learning-based runtime scheduler~\cite{ml}, and develop a novel online
scheduling module in which any appropriate machine learning classifier
can be utilized for the runtime offloading scheduler.
%
First, we define application programming interfaces (APIs) to monitor and
acquire dynamic features, such as data sizes, network latency and
bandwidth, and the status of external devices.
%
Furthermore, our work supports an online training mechanism for
the machine learning-based runtime scheduler such that it learns from
observation of previous offloading decisions, and a policy that
dynamically adapts scheduling decisions at runtime.\\
%
\indent To demonstrate its practical applicability, we integrated the
proposed machine learning-based runtime scheduler with an existing
Java-based, offloading-capable code refactoring framework,
\textit{DPartner}~\cite{dpartner}.
%
Originally, the offloading-capable mobile applications generated by
DPartner depend on static (or user-provided) input to decide whether to
execute offloadble computations (i.e. Java classes) locally or remotely.
%
By combining this paper's machine learning-based runtime scheduler with
these applications, offloading decisions are dynamic and do not require
user input.
%
We have implemented an online-scheduled DPartner prototype, and used it
to perform quantitative experiments with Android mobile devices and
applications to quantitatively evaluate the cost and performance for
three machine learning algorithms: instance-based learning, perceptron,
and na\"{i}ve bayes.
%
Theses are evaluated with respect to classifier training time,
classification time, and scheduling accuracy.
%
Even though there have been prior related studies which suggest
utilizing machine learning techniques for mobile computing environments,
to the best of our knowledge, our work is the first to consider an
online training mechanism for the machine learning-based runtime
scheduler, and to demonstrate with a end-to-end system performance and
cost of various machine learning algorithms for the runtime scheduler of
mobile offloading tasks.\\
%
\indent The rest of the paper is organized as follows.
%
In Section II, we overview prior research efforts on 
mobile offloading frameworks as well as the use of machine
learning techniques for scheduling problems from various domains.
%
Section III summarizes our previous work which proposed the machine
learning based runtime scheduler for mobile offloading framework, and 
motivates the concept of the online machine learning-based
runtime scheduler.
%
In Section IV and V, we explain and evaluate our implementation of the
online machine learning (ML) scheduler.
%
Section VI describes the current and potential applications for
our work.
%
Finally, we conclude the paper in Section VII.
%
\section{Related Works}
%
\subsection{Adaptive Mobile Offloading Frameworks}
%
Many approaches on adaptive mobile offloading framework have been
proposed to address scheduling problems on dynamic environments.
%
In ~\cite{shigeru}, a prediction heuristic uses linear funtions to
estimate the local and remote processing time as well as the data
transfer time.
%
The remote server updates these linear functions unsing least-squares
method and returns the updated prediction funtions to the mobile client,
then these functions are used to compare the performance between local
processing and offloading.
%
Gu et al.~\cite{xiaohui} try to relieving the memory restriction fo the
mobile device by adaptively making offloading decisions with help from
the fuzzy control model, called Offloading Inference Engine (OLIE).
%
OLIE monitors the available memory margin of the mobile device and
network bandwdith, and maps them into the offloading decision
specifications defined by the application developer so that when the
present condition matches the specified rule, the mobile workloads are
offloaded to the remote server.
%
Kwon et al.~\cite{kwon} consider a simple rule-based
scheduler in which the framework decides to offload the mobile
computation only when the data transfer size is higher than a certain
threshold.\\
%
\indent Although the aforementioned studies take dynamic features
from hardware or network level (i.e. available memory size, network
bandwidth) into account, they still depend on the predefined static
decision rules or cost models while preventing the scheduler from
adapting to dynamic conditions on runtime.
%
In contrast, our approach do not rely on any predefined specifications
or prior knowledge of the mobile application.
%
Instead, we consider machine learning techniques for the adaptive mobile
offloading scheduler in which the scheduler can be trained on and 
dynamically make offloading decisions on runtime. 
%
\subsection{Machine Learning Techniques for Runtime Scheduler}
%
Various areas such as heterogeneous computing platforms, grid computing
systems, and data center have used machine learning techniques to
address dynamic scheduling problems.
%
In~\cite{zheng}, machine learning techniques are used to provide a
compiler-based, automatic and portable predictor for multi-core
processors.
%
In order to decide the optimal number of threads and scheduling policy,
the framework used a feed-forward artificial neural network and a
multi-class support vector machine model, respectively.
%
Berral et al.~\cite{josep} propose an energy-aware
data center through server consolidation by turning off idle servers
with assistance from machine learning based scheduling.
%
The scheduler predicts the future performance of the jobs and power
consumption in the resulting job allocation using linear regression
algorithms.
%
This framework uses artificial neural networks for the performance
modeler which predicts task computation and data communication costs,
and this modeler is used by the directed acyclic graph to determine an
appropriate schedule.\\
%
\indent Along with the machine learning-based runtime scheduler, we
further consider the adaptive online training mechanism which stretches
and shrinks the length of the training period according to the scheduling
accuracy.
%
\section{Runtime Scheduler for Mobile Offloading System}
%
In this section, we summarize our previous work on the machine
learning-based runtime scheduler for mobile offloading framework.
%
In our previous work, we noticed the offloading performance dependency on
various dynamic features such as data size and network conditions.
%
Then, we suggested applying machine learning techniques to the runtime
scheduler for mobile offloading framework by showing the performance and
cost among various machine learning algorithms. 
% 
\subsection{Offloading Performance}
%
In our previous work~\cite{ml}, we validated the necessity and efficacy
of the runtime scheduler for mobile offloading framework through
detailed measurement experiments.
%
With the OpenCL-based mobile offloading framework~\cite{ocloff}, we
performed various experiments using four different OpenCL workload
kernels used in a variety of areas such as image processing filters and
mathematical simulations.
%
Also, in order to observe the impact of different network conditions on
the offoading performance, we configured different network conditions:
local area network, campus network, and wide area network (i.e. Amazon
EC2 cloud).
%
In the evaluation, we verified that different network conditions cause
significantly different offloading performance.
%
In most cases, offloading to the remote resource located in local area
network has better performance than local processing in four OpenCL
workload kernels used for the experiments.
%
In contrast, offloading to the remote resource located in campus network
and Amazon EC2 cloud, where have much limited network conditions than
local area network, can exhibit longer execution time than local
processing according to the size of data transfer.\\ 
%
\indent It is worth noting that each OpenCL workload kernel shows
the different performance, even though they process the similar size of
data.
%
This is because each kernel has different computational complexities so
they gain the different amount of performance improvement while paying
the same cost to send the data to the remote resource.
%
These results show that there exists the offloading performance
variation over different network conditions and OpenCL workload kernels.
%
Consequently, proper scheduling can have a significant impact on the
offloading performance and mobile offloading framework requires the
support from the runtime scheduler.
%
\subsection{Machine Learning-based Runtime Scheduler}
%
Based on our observation, we applied machine learning techniques to the
runtime scheduling problem for mobile offloading framework.
%
For doing this, we first chose a set of relevant attributes which have
an impact on making offloading decisions.
%
Also, by running the OpenCL-based offloading framework with different
network configurations, OpenCL workload kernels, and data size, we
collected a total 640 data instances to train and test the classifiers
of various machine learning algorithms.
%
Using the gathered dataset, we trained various machine learning
classifiers with \textit{Weka}, a Java-based open source package for
machine learning techniques.
%
Finally, we implemented the machine learning-based runtime scheduler by
building the trained machine learning classifiers onto the
OpenCL-based mobile offloading system.\\
%
\indent In order to evaluate the machine learning-based runtime
scheduler for mobile offloading framework, we deployed the OpenCL-based
offloading system under various network bandwidth controlled by a
network characteristic tool called \textit{Traffic Control} (TC).
%
In our evaluation, we observed that most of the machine learning-based
schedulers show the reasonably high scheduling performance by achieving
higher than 80\% of the scheduling accuracy.
%
Especially, Instance-Based Learning has the most accurate scheduling
performance among various schedulers showing 92\% of the scheduling
accuracy.
%
Compared with other machine learning-based schedulers, furthermore,
Instance-Based Learning exhibits a fairly small penalty, which is the
additional cost in terms of the execution time and energy consumption
when the scheduler makes incorrect decisions.
%
\section{Challenge on Online Training for Machine Learning-based Mobile
Offloading Scheduler}
%
The main goal in this work is to construct the machine learning-based
runtime scheduler with online training for mobile offloading framework.
%
In this section, we explain the difference between offline and online
training for the machine learning technique.
%
Also, we describe the challenge on the online training mechanism for the
machine learning-based runtime scheduler.
%
\subsection{Offline vs. Online Training}
%
Machine learning technique is a branch of artificial intelligence
through which a system can learn from previous experiences proactively
and predict the future actions of the target system.
%
In fact, there exist two possible ways to train the machine learning
classifier: \textit{offline} and \textit{online} training.
%
In offline training, the machine learning classifier can be trained
using a set of the pre-collected static data.
%
Once the machine learning classifier is trained in the initial training
phase, the classifier does not change its prediction behavior.
%
It is therefore difficult to reflect the unseen situations or conditions
which have not been trained in the initial training phase.
%
For that reason, offline machine learning is trained through a large set
of data which covers as many cases as possible in order to accomplish
the high prediction performance.\\
%
\indent On the other hand, the online machine learning technique does
not depend on any pre-trained classifiers to approximate or predict 
the future behaviors of the target system.
%
Instead, online machine learning trains its classifier at a time
when a new data instance arrives in.
%
More specifically, the classifier of online machine learning is trained
whenever the result of the comparison between the prediction and actual
behavior is available.
%
Thus, the main challenge of online machine learning is to deliver the
prediction correctness into the training process, so that it can train
the classifier continuously based on the prediction correctness feedback.
%
\subsection{Requirement for Online Training Machine Learning-based
Mobile Offloading Scheduler}
%
As mentioned in the previous subsection, the online training mechanism has
to maintain its own continuous feedback channel from the examination of
whether the prediction made by the classifier is correct, and if not,
which prediction should have made in the case where multiple predictions
are available.  
%
However, it can be too expensive to feedback with the correct
prediction, since the system may have to try all of the possible cases
to figure out the correct prediction.\\
%
\indent In the case for the mobile offloading scheduler, even though
there exist only two possible cases: offloading and local processing,
the mobile platform also has to pay for both offloading and local
processing.  
%
It is therefore required to minimize the online training phase while
guaranteeing the reasonable scheduling accuracy.
%
In this paper, we address these challenges by proposing the adaptive
online training mechanism in which the training phase stretches and
shrinks dynamically according to the scheduling accuracy. 
%
\section{Architecture of Machine Learning-based Runtime Scheduler with
Online Training}
%
In this section, we describe the architecture and main modules of the
machine learning-based mobile offloading scheduler with online training.
%
Then, we describe implementation details on the adaptive online training
mechanism.
%
Finally, we explain how the proposed machine learning-based mobile
offloading scheduler can be integrated with mobile offloading frameworks,
using DPartner as a concrete scenario.
%
The overall architecture and main modules of the machine learning-based
mobile offloading scheduler with online training are illustrated in
Figure 1.
%
\begin{figure}
\centering
\includegraphics[height=5.1cm, width=7.6cm]{Figure/figure1}
\caption{Overall architecture of the ML-based mobile offloading
scheduler with online training. The dotted lines indicate the
application and network features flow path, and the solid lines are the
application workloads or scheduling-related commands flow path.}
\end{figure}
%
\subsection{Architecture of the Machine Learning-based Mobile Offloading
Scheduler}
%
As depicted in Figure 1, the overall architecture consists
of four main modules: computation switch, runtime scheduler, machine
learning classifier, and the trainer for the ML classifier.
%
These four main modules interact with each other to execute and
schedule offloadable tasks, and to train the machine learning
classifier. 
%
At runtime, the system operates in either of two different phases:
\textit{normal operation phase} and \textit{online training phase}.
%
In the normal operation phase, first, the computation dispatcher
receives and offloadable computation (\textcircled{1}).
%
Then, according to the decision provided by the scheduling module
(\textcircled{2}), it forwards this computation to the appropriate
execution unit (\textcircled{3}): either a local computing unit, or a
remote computing unit (through the network interface).
%
In contrast, in the online training phase, the offloadable
computation is forwarded to \textit{both} execution units; the
computation dispatcher records the performance of both, and feeds back
the comparison between offloading and local processing to the trainer
(\textcircled{4}).
%
Based on the feedback from the dispatcher, the classifer trainer updates
the machine learning classifier{\textcircled{5}).
%
The implementation details for these modules are as follows: \\
%
\textbf{Computation dispatcher.} This module has the
responsibility to forward offloadable tasks either to the
network interface (for offloading) or to the local computing units (for
local processing) according to the scheduling status of each offloadable
computation stored in scheduling table.
%
In the online training phase, this module provides feedback to the
classifier updater in the machine learning classifier trainer module, by
comparing the performance between offloading and local processing and
recording the approach that leads to best performance.\\
%
\textbf{Runtime scheduler.} Scheduling offloadable computations
requires the profiling of internal and external dynamic features, such
as data size of inputs to the task and network latency and bandwidth
conditions.
%
The scheduling process itself results in additional costs in terms of
runtime overhead and energy consumption.
%
Thus, there exists a trade-off between the scheduling performance and
cost: as coarse-grained scheduling is cheaper than frequent
scheduling, but can lead to worse scheduling accuracy.    
%
For this reason, we consider two scheduling strategies.
% Heungsik: I don't fully understand what you meant in the sentence below
The first strategy makes scheduling decisions offloadble tasks whenever the
application executes these mobile computations.
%
We refer to this strategy as \textit{on-demand scheduling}.
%
Another strategy is the \textit{periodic scheduling}, in which
offloadable tasks are rescheduled asynchronously with an adaptive
scheduling interval.
%
In the periodic strategy, the scheduling decision for future offloadable
tasks is done at specific intervals, and is not synchronized with the
invocations of the offloadable tasks from the application.
%
% Heungsik: it's unclear why periodic would be better from your explanation.
% you may need an example.
In order to prevent unnecessarily frequent scheduling, the
scheduling interval controller changes the scheduling interval according
to network conditions. The policy used is such that the interval becomes shorter if the
variation of network bandwidth is less than a threshold.
% Heungsik: this is vague - you need to explain this policy in more details.
% what's a long interval mode? how does the interval increases/decreases?
% what do you do with the N measurements? how do you measure bandwidth?
Otherwise, the scheduling frequency leaves in a long interval mode.
%
To end this, the scheduling interval controller stores a time series with a history of the previous
\textit{N} network bandwidth measurements.\\
%
% Heungsik: 
% it's unclear how the classifier and the scheduling table interact
% the subsection below is not very clear either.
\textbf{Machine learning classifier.} The machine learning classifier is
in charge of making decisions on offloading or local processing for
offloadable tasks by using the attributes obtained by
the network and application profiler.
%
Even though it is possible to adopt various attributes
from internal (application) and external (network, remote resources) environments, for
the current implementation, we employ two attributes: the size of data
to be sent to the remote resource, and the network bandwidth.
%
% Heungsik: sentence below not clear to the reader. needs to be improved
It is also worth noting that, in the periodic scheduling mode, the
real-time measurement of the data size of the mobile computations is
unfeasible because the scheduling process is triggered periodically, but
asynchronously regardless of the invocations of the mobile computations.
% Heungsik: how is this calculated? where is it stored? over how many samples?
% how do you anticipate (you should say predict instead I think) the maximum
% and minimum from these values? you need to be more specific.
In the periodic scheduling mode, instead, the application profiler
calculates the mean and standard deviation of the previous measurements
to anticipate the maximum and minimum possible data size.
% Heungsik: what do you mean by both classifications? need to clarit\fy
Then, the machine learning classifier makes the decision on offloading
only when both classifications with the maximum and minimum possible
data size agree on offloading.\\
%
\textbf{Machine learning classifier trainer.} With the feedback on the
performance comparison between offloading and local processing from the
computation dispatcher, the machine learning classifier trainer updates
the machine learning classifier.
%
In order to compare the performance between offloading and local
processing, the trainer creates one separate thread for local
processing, so that offloading and local processing can be executed
concurrently.
%
Then the computation dispatcher measures the execution time for both
offloading and local processing to compare the performance and provide
feedback into the classifier updater.
%
Finally, with the feedback from the computation dispatcher and the
attributes from the profilers, the classifier updater trains the
classifier.
% Heungsik: overall, I think the details above are a bit repetitive -
% for instance, feedback from the dispatcher/router is mentioned a few times - and
% you don't actually present a lot of details.
\subsection{Adaptive Online Training Mechanism}
%
\begin{figure}
\centering
\includegraphics[height=3.3cm, width=8.5cm]{Figure/figure2}
\caption{An example of the adaptive online training mechanism. For this
example, we set 70\% of the scheduling accuracy threshold and 5 of the
minimum number of the mobile computation executions.}
\end{figure}
%
One of the main contributions of this work is the adaptive online
training mechanism which allows the training phase duration to stretch and shrink
dynamically according to the scheduling accuracy.
% Heungsik: before you go through this example, you need to describe how
% the algorithm works.
Figure 2 illustrates an example of how the adaptive online training
mechanism works.
%
% Heungsik: you used "N" earlier, use a different variable here
In this example, we set the minimum number of the executions of the
mobile computations in one period to 5.
%
% Heungsik: how do yo measure accuracy? how should you configure a threshold?
First of all, the training phase (empty bars) in a period
continues until the scheduling accuracy is higher than a certain
threshold.
% Heungsik: I do not understand the sentence below at all
In order to avoid 100\% of the scheduling accuracy at just one training,
we insert a dummy training which does nothing with the training process,
but indicates an incorrect decision. 
%
By adding this dummy training into the measurement of the scheduling
accuracy, more than one training in a period can be guaranteed.\\
%
\indent Once the training phase finishes, the normal operation phase
follows by starting the scheduling process until the period is
completed.
% Heungsik: it's unclear why you chose 70% and why no error happened.
% you need to describe the setup/initial conditions/assumptions of your 
% example before you begin analyzing it
Since we set 70\% of the accuracy threshold for this example and no
decision error happened in the first and second period, the machine
learning can be trained for first three of executions and the rest of
the executions (two for the first period and seven for the second
period) are done in the normal operation phase. 
% Heungsik: why do you increase by a constant? why decrease by period times #errors?
% you are describing the mechanism without providing much justification for your
% choices, or guidance as to how to pick up values for thresholds, etc. 
Furthermore, because there was no decision error in the first and second
period, the next number of the executions of the mobile computation
increases by 5 which is the minimum number of the executions in a
period, thus, the number of the computation executions for the second
and third period becomes 10 and 15, respectively.
%
In the second period, however, as one incorrect decision has been
occurred, the training phase holds for six executions when the
scheduling accuracy becomes higher than 70\%, and the number of the
executions in the fourth period decreases by 5 which is the minimum
number of the executions in a period multiplied by the number of the
occurred errors (in this case, 1). 
%
The pseudo-code of the adaptive online training mechanism is shown in
Figure 3.
%
\begin{figure}
\algsetup{indent=1.0cm}
\begin{algorithmic}[1]
\STATE{\textit{$//$ switch the training and normal operation phase}}
\WHILE{$one$ $period$ $is$ $NOT$ $finished$}
	\IF{$it$ $is$ $in$ $normal$ $operation$ $phase$}
		\STATE {$do$ $scheduling$}
	\ELSE
		\IF{$accu_{curr}$ $is$ $higher$ $than$ $th_{accu}$}
			\STATE{$switch$ $normal$ $operation$ $phase$}
		\ELSE
			\STATE{$stay$ $training$ $phase$}
		\ENDIF
	\ENDIF
\ENDWHILE
\STATE
\STATE{\textit{$//$ calculate the length of the next period}}
\IF{$errors$ $happened$}
	\STATE{$period_{next}$$\gets$$period_{curr}$$-$$($$period_{min}$$\times$$n_{err}$ $)$}
\ELSE
	\STATE{$period_{next}$$\gets$$period_{curr}$$+$$period_{min}$}
\ENDIF
\end{algorithmic}
\caption{Adaptive online training mechanism}
\end{figure}
%
\subsection{Integration with On-Demand Java-based Offloading Framework}
%
To demonstrate the applicability of this approach, we integrated the modules of the
machine learning-based mobile offloading scheduler into the DPartner 
mobile application framework, which is capable of automatically refactoring
Java-based applications to identify offloadable classes.
%
Given an Android mobile application, first of all, DPartner examines its
bytecode to classify the Java classes into the anchored and offloadable
classes, so it can be guaranteed that the anchored classes are executed
on the mobile device while directly using a variety of the local sensors
such as the GUI display, camera, accelerator, and GPS.
%
Also, DPartner rewrites the bytecode for the offloadable classes to
implement a special type of the program structure to support on-demand
offloading.
%
Then, DPartner packages the files such as images, xml files, external
libraries, and rewritten bytecode for the offoadable classes, and
generates two separate objects which are deployed into the mobile device
and the remote server, respectively.\\
%
\indent With respect to scheduling, however, the offloading-capable
Android applications generated by DPartner requires either static or
user-provided decisions. 
%
However, static scheduling becomes inaccurate if conditions change, and it is impractical that the
mobile user monitors the internal and external environments and
schedules each offloadable mobile computations at runtime.
% Heungsik: you are repeating yourself a bit below. You need to describe how
% you were able to integrate your approach without requiring deep changes to DPartner.
We address this challenge by integrating the modules of
the machine learning-based runtime scheduler with the on-demand
Java-based offloading framework.  
%
By combining the machine learning-based runtime scheduler with these
applications, the mobile user can be free of the burden of the scheduling
tasks.
%
\section{Evaluation}
%
In this section, we evaluate the implementation of the machine
learning-based mobile offloading scheduler with online training with
respect to the scheduling accuracy and classifier training cost.
%
In order to compare the performance and cost among the different
categories of machine learning algorithms, we utilize three machine
learning algorithms: instance-based learning, single layer perceptron,
and na\"{i}ve bayes.
%
\begin{figure*}[ht]
\centering
\subfigure[Training time] {
\includegraphics[height=4.0cm, width=5.6cm]{Figure/figure4}
}
\subfigure[Classification time] {
\includegraphics[height=4.0cm, width=5.6cm]{Figure/figure5}
}
\subfigure[Scheduling accuracy] {
\includegraphics[height=4.0cm, width=5.6cm]{Figure/figure6}
}
\caption{Performance and cost comparison for three machine learning
algorithms}
\end{figure*}
%
\subsection{Experimental Setup}
%
Even though high dimensional machine learning algorithms such as
decision tree, multilayer perceptron, and support vector machine can
achieve more accurate scheduling performance, they might be too
expensive to be used for the mobile offloading scheduler.
%
Based on the intuitive observation on the algorithm complexity, we
selected three machine learning algorithms: instance-based learning,
single layer perceptron, and na\"{i}ve bayes.\\ 
%
\indent Our hardware setup consists of the mobile client and
remote server which are connected through a wireless router.
%
We have utilized Android tabletPC, Nexus 5 equipped with 2.3GHz
quad-core processor and 2GB RAM, and running Android KitKat as the
mobile client.
%
For the remote server, we used a workstation with Intel 3.0GHz Core2 Duo
processor and 8GB memory which is running Linux OS.
%
In order to emulate various network conditions, furthermore, we
configured different network bandwidth using Traffic Control
(TC)~\cite{tc}, a network tool which provides functionality to control
network traffic by priortizing network resources and using concepts of
traffic classification, queue disciplines, and quality of service.
%
Also, for the mobile application used in the evaluation, we created
a synthetic benchmark application, matrix multiplication, and DPartner
rewrote it as the offloading-capable application.
%
Though, theoretically, DPartner is applicable to any types of Android
mobile applications, it is not possible to intentionally change the data
size and the amount of computation for the real-world applications.
%
With matrix multiplication, we are able to easily vary the data size and
the amount of computation by manually controlling the matrix size.
%
\subsection{Overhead of training and classification}
%
Since our machine learning-based mobile offloading scheduler keeps
training the classifier, which leads some runtime overhead, we
observed the cost to train the machine learning classifier.
%
As shown in Figure 4(a), instance-based learning has the shortes
classifier training time among three machine learning algorithms.  
%
In fact, the basis for the classification of instance-based learning is
the instance database, where previously experienced cases are stored.
%
Instead of training the explicit classifier, therefore, instance-based
learning adds a new instance to the database for the future
classification raising relatively small training overhead.
%
On the other hand, na\"{i}ve bayes with 1000 instances of database has
the worst training overhead. 
%
For the algorithm perspective, na\"{i}ve bayes measures the
probability density for the given classes with the mean and standard
deviation, and chooses the class with the highest probability.
the highest probability.
%
Thus na\"{i}ve bayes calculates the mean and standard deviation
throughout the previous instances for each class whenever a new instance
is trained.
%
Consequently, na\"{i}ve bayes with 1000 instancs, which requires
relatively heavy calculations for the mean and standard deviation, has
bigger training overhead than other machine learning algorithms.\\
%
\indent Also, Figure 4(b) shows the classification time that the machine
learning classifier consumes to make a decision.
%
Similarly as the training time, na\"{i}ve bayes shows bigger overhead
than other machine learing algorithms.
%
In fact, we used the Gaussian distribution to calculate the probability
density for each class with the mean and standard deviation value.
%
Therefore, the classification for na\"{i}ve bayes entails the complex
arithmetic operations such as the exponential function and the square root
which take longer than addition, multiplication, or comparison.
%
For that reason, na\"{i}ve bayes has the worst classification overhead.
%
Note that perceptron has remarkably low classification overhead compared
with other machine learning algorithms. 
%
For perceptron, the classification process involves calculating the
output from a multivariable linear equation consisting of the attributes
weighted by the coefficients, which requires the insignificant amount of
the computation. 
%
As a result, perceptron shows the lowest cost in terms of the
classification time amongst three machine learning algorithms.
%
\subsection{Scheduling Accuracy}
%
We also investigated the scheduling accuracy of three machine learning
algorithms.
%
For the unbiased evaluation, we turned off the adaptive online training
mechanism and the training phase and normal operation phase were
uniformly switched in one period (5 trainings and 15 normal operations)
and 10 periods were repeated for the average.
%
Also, in order to observe the impact of the dynamic network condition
and data size on the scheduling accuracy, we changed the network
bandwidth randomly among 1MB/s, 2.5MB/s, 5MB/s, and 9.5MB/s with
a same interval and each computation processes the different matrix size
having the different data size. 
%
In this experimental setup, we observed how accurate each machine
learning makes decisions in the normal operation phase.\\
%
\indent As you can see in Figure 4(c), instance-based learning achieves
the highest scheduling performance, showing 87\% of the scheduling
accuracy.  
%
As we mentioned earlier, instance-based learning compares a new
scheduling problem with the all of the stored instances in the database
to find out the most similar case in the database.
%
It is because that instance-based learning can hardly miss any
information from the previously stored instances.
%
On the other hand, na\"{i}ve bayes has the worst scheduling accuracy
which is lower than 80\% of the accuracy.
%
The reason is that the classification of the probabilistic machine
learning algorithms is based on the statistics of attibutes of the
previous instances such as the mean and standard deviation.
%
Thus it is possible that the probability-based machine learning
algorithms can overlook the edge of previously seen instances, which
causes the performance degradation for the prediction problem.
%
\section{Use Case}
%
We applied our machine learning-based mobile offloading scheduler with
online training to Go, the two players board game which is available in
Google Play.
%
In Go game shown in Figure 5, the next stone position of the competitor
is calculated through the Monte Carlo tree search algorithm, thus the
offloading-capable version of the Go game offloads the Monte Carlo
algorithm to the remote server according to the board size and network
bandwidth.
%
Also, for Go game, the quick reactivity from the competitor is one of
the important aspects to play the game seamlessly.
%
So, the on-demand scheduling strategy can cause relatively high overhead
by doing the scheduling process for every competitor turn.
%
For that reason, we utilized the periodic scheduling strategy for Go
game.\\
%
\indent Another possible application is the optical character
recognition (OCR) application with the translation between different
languages.
%
Character recognition and language traslation technologies include
the complex mechanisms such as pattern recognition and data mining which
are suitable for offloading.
%
Hence, the flexibility of where to execute these complex algorithms
according to the image size and network conditions will help the mobile
device improve the performance and save energy consumption.
%
\begin{figure}
\centering
\includegraphics[height=5.0cm, width=4.0cm]{Figure/figure7}
\caption{Go game generated by DPartner.}
\end{figure}
%
\section{Conclusion and Future Work}
%
In this paper, we proposed the machine learning-based mobile offloading
scheduler with the online training mechanism.
%
First, we modularized the machine learning-based mobile offloading
scheduler to generally apply to any types of mobile offloading
frameworks.
%
Also, we suggested the adaptive online training mechanism in which the
training phase and normal operation phase are dynamically switched
according to the scheduling accuracy.
%
To evaluate our work, we applied the machine learning-based mobile
offloading scheduler with online training to the Java-based on-demand
offloading framework.
%
Also, we utilized three different machine learning algorithms for the
offloading scheduler and compared the overhead and performance in terms
of the training time, classification time, and scheduling accuracy.
%
In the evaluation, we observed that instance-based leaning and na\"{i}ve
bayes have higher than 80\% of the scheduling accuracy with the
reasonable overhead.\\
%
\indent For the future work, we plan to apply our work to various types
of mobile offloading frameworks with more machine learning algorithms
and target real-world applications.
%
\section*{Acknowledgment}
This material is based upon work supported in part by the National Science
Foundation under Grant No. 0910812, 0758596, 0855031, 1265341, and
1339737.
%
Any opinions, findings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily reflect
the views of the National Science Foundation.
%
\bibliographystyle{IEEEtran}
\bibliography{ipccc14}
\end{document}



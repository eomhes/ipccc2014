\documentclass[10pt, conference, compsocconf]{IEEEtran}
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{cite}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{subfigure}

\begin{document}
\bibliographystyle{IEEEtran}

%\title{Online Training Machine Learning based Decision Maker for Mobile
%Offloading Framework}
\title{Machine Learning based Runtime Scheduler with Online-Training
Mechanism for Mobile Offloading Framework}


\author{\IEEEauthorblockN{Heungsik Eom, Renato Figueiredo}
\IEEEauthorblockA{Advanced Computing and Information Systems Laboratory\\
Electrical and Computer Engineering\\
University of Florida, Gainesville, Florida, USA\\
\{hseom, renato\}@acis.ufl.edu}
\and
\IEEEauthorblockN{Huaqian Cai, Gang Huang}
\IEEEauthorblockA{Operating System and Middleware Laboratory\\
School of Electronics Engineering and Computer Science\\
Peking University, Beijing, China\\
\{caihq12, hg\}@pku.edu.cn}
}

\maketitle

\begin{abstract}
%
%OpenCL has emerged as the open standard for parallel programming for
%heterogeneous platforms enabling a uniform framework to discover,
%program, and distribute parallel workloads to the diverse set of compute
%units in the hardware.
%
%For that reason, there have been efforts exploring the advantages of
%parallelism from the OpenCL framework by offloading GPGPU workloads
%within an HPC cluster environment.
%
%In this paper, we present an OpenCL-based remote offloading framework
%designed for mobile platforms by shifting the motivation and
%advantages of using the OpenCL framework for the HPC cluster environment
%into mobile cloud computing where OpenCL workloads can be exported from
%a mobile node to the cloud.
%
%Furthermore, our offloading framework handles service discovery, access
%control, and data privacy by building the framework on top of a social
%peer-to-peer virtual private network, SocialVPN. 
%
%We developed a prototype implementation and deployed it into local- and
%wide-area environments to evaluate the performance improvement and
%energy implications of the proposed offloading framework.
%
%Our results show that, depending on the complexity of the workload and
%the amount of data transfer, the proposed architecture can achieve more
%energy efficient performance by offloading than executing locally.
\end{abstract}

\begin{IEEEkeywords}
Mobile platform, computation offloading, machine learning, runtime
scheduler, online training
\end{IEEEkeywords}

\section{Introduction}
%
Over the last decade, mobile offloading techniques have emerged as
intelligent means to overcome the constraints of the limited resources
from mobile platforms, smartphones and tabletPCs, so that these types of
devices delegate computationally intensive computing tasks to more
powerful external resources such as personal workstations or cloud
servers.
%
Initially, most of research interests on mobile offloading techniques
have focused on core mechanisms in which \textit{what to offload} and
\textit{how to offload} have been primarily considered. 
%
The research community has studied various approaches to implement mobile
offloading frameworks which fall in the following categories:
application partitioning~\cite{spectra, maui, cuckoo}, thread
migration~\cite{clonecloud, comet}, application migration~\cite{hung},
and distributed offloading frameworks~\cite{mmr, sonora, serendipity}.\\
%
\indent However, one important fact from an offloading performance
standpoint of view is that benefits from offloading
computation-intensive portions of mobile applications can be influenced
by various internal and extenal factors such as application
requirements, network conditions, and computing capabilities of mobile
or external devices.
%
Thus, \textit{whether to offload or execute locally} needs to be
decided periodically by monitoring aforementioned dynamic features on
runtime.
%
Otherwise, incorrect offloading decisions may cause the performance
degradation or worse energy consumption.
%
For that reason, research focuses have been naturally shifted into
dynamic scheduling or decision making problems for mobile offloading
framework.
%
For example, Kwon et al.~\cite{kwon} consider a simple rule-based
scheduler in which the framework decides to offload the mobile
computation only when the data transfer size is greater than a certain
threshold.
%
MAUI~\cite{maui} utilizes a linear regression model among predefined
features to make offloading decisions.\\
%
\indent Even though these studies on the runtime scheduler for mobile
offloading system take dynamic features such as data transfer size or
network conditions into account to make offloading decisions, it is
impractical for these approaches to build a globally well-defined
offloading decision policy while considering all possible cases against
dynamic mobile environments.
%
Furthermore, it is difficult to generalize the above efforts for various
mobile application use case scenario, since different applications need
to have different offloading decision policies due to different
application requirements or characteristics.
%
Therefore, in practice, it is necessary for the scheduler to learn
from self-observation of the previous decision correctness and to
dynamically adapt the decision policy on runtime, thereby an identical
decision model can be \textit{generally} applied to various mobile
applications without any predefined decision policies.\\
%
\indent In this paper, we aim to develop a general framework for a
runtime adaptive scheduler for mobile offloading framework by
employing various types of machine learning techniques
%
By applying machine learning techniques to scheduling problems
for mobile offloading framework, the machine learning classifier can
make decisions on whether mobile computations should be offloaded to
external resources or executed locally.
%
To this end, we modularized our previous work on the machine learning
based runtime scheduler~\cite{ml} in which any appropriate machine
learning classifiers can be utilized for the runtime scheduler for
mobile offloading framework.
%
This work can be plugged and played with any types of mobile offloading
frameworks in conjunction with the well-defined APIs to monitor and
acquire dynamic features such as data size, network conditions, or the
status of external devices. 
%
Furthermore, our work supports an online training mechanism for
the machine learning based runtime scheduler such that it learns from
observation on the previous offloading decision performance, and
dynamically adapts its decision policy on runtime.\\
%
\indent As part of the modularization effort, we integrated the
modularized machine learning based runtime scheduler into the Java based
mobile offloading system called \textit{Dpartner}~\cite{dpartner}.
%
Originally, Dpartner depends on the web based user interface to offload
or execute the offloadable tasks(i.e. classes) in local, so the user
schedules them manually by manipulating the UI in a drag-and-drop way.  
%
By combining the machine learning based runtime scheduler with Dpartner,
the user can be free of the scheduling task.
%
Based on this integration, we evaluated the cost and performance for
three machine learning algorithms, instance based learning, perceptron,
and na\"{i}ve bayes with respect to classifier build time,
classification time, and scheduling accuracy.
%
Even though there have been prior related studies which suggest
utilizing machine learning techniques for mobile computing environments,
to the best of our knowledge, our work is the first to consider the
online training mechanism for the machine learning based runtime
scheduler for mobile offloading framework and demonstarate the
performance and cost of various machine learning algorithms for the use
of the runtime scheduler of mobile offloading framework.\\   
%
\indent The rest of the paper is organized  as follows.
%
In Section II, we overview prior research efforts on offloading decision
problems in mobile offloading framework as well as the use of machine
learning techniques for scheduling problems from various domains.
%
Section III summarizes our previous work which proposed the machine
learning based runtime scheduler for mobile offloading framework.
%
Section IV motives the concept of the online machine learning based
runtime scheduler.
%
In Section IV and V, we explain and evaluate our implementation of the
online ML scheduler.
%
Also, Section VI describes the current and potential applications for
our work.
%
Finally, we conclude the paper in Section VII.
%
\section{Related Works}
%
\section{Adaptive Scheduler for Mobile Offloading System}
%
In this section, we summarize our previous work on the machine learning
based runtime scheduler for mobile offloading frameowork.
%
In our previous work, we noticed the offloading performance dependency on
various dynamic features.
%
Then, we suggested applying machine learning techniques to the runtime
scheduler for mobile offloading framework by showing the performance
difference among various machine learning algorithms. 
% 
\subsection{Offloading Performance}
%
In our previous work~\cite{ml}, we demonstrated the performance
dependancy
%

\subsection{Machine Learning based Runtime Scheduler}
%
\section{Challenge on Self-Training ML based Runtime Scheduler for
Mobile Offloading System}
%
\subsection{Offline vs. Online}
%
\subsection{Requirement for Self-Training ML based Runtime Scheduler for
Mobile Offloading System}
%
\section{Implementation of Self-Training ML based Runtime Scheduler}
%
\subsection{Integration with Java based Mobile Offloading System}
%
\subsection{Self-Training Mechanism}
%
\section{Evaluation}
%
\subsection{Training Cost}
%
\subsection{Offloading Decision Performance}
%
\section{Use Case}
%
\section{Conclusion and Future Work}
% 
%\section*{Acknowledgement}
%This material is based upon work supported in part by the National Science
%Foundation under Grant No. 0910812, 0758596, 0855031, and 1265341.
%
%Any opinions, findings, and conclusions or recommendations expressed in
%this material are those of the author(s) and do not necessarily reflect
%the views of the National Science Foundation.
%
%\bibliographystyle{IEEEtran}
\bibliography{ipccc14}
\end{document}


